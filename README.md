# Отчет по Практической работе 4.1
## Написание простого DAG для запуска dbt-проекта

### Цель работы
Научиться создавать, настраивать и запускать Airflow DAG для автоматизации выполнения команд проекта dbt (data build tool) с целью трансформации данных. Освоить интеграцию инструментов оркестрации (Airflow) и трансформации (dbt) в контейнеризированной среде.

---

### Выбранный вариант выполнения
**Вариант 2. Локальное решение (Docker)**

**Обоснование выбора:**
Выбран локальный вариант развертывания с использованием Docker, так как он предоставляет полный контроль над инфраструктурой без необходимости привязки к облачным провайдерам и биллингу. Это позволяет глубже понять взаимодействие сервисов (Airflow, PostgreSQL) на уровне сети и конфигурации, а также проводить разработку и отладку в офлайн-режиме.

**Тема задания (Вариант 13):** Анализ качества обслуживания клиентов.

---

### Краткое описание решения
Реализован **ELT-процесс** (Extract, Load, Transform), упакованный в Docker-контейнеры.

**Архитектура:**
1.  **Storage:** PostgreSQL используется как хранилище данных (Data Warehouse).
2.  **Transformation:** dbt (Data Build Tool) отвечает за логику преобразования данных.
    *   *Staging:* Очистка сырых данных, переименование полей.
    *   *Marts:* Расчет бизнес-метрик (CSAT, NPS, CES) по датам.
3.  **Orchestration:** Apache Airflow управляет запуском dbt-моделей по расписанию.
4.  **Management:** pgAdmin 4 используется для администрирования базы данных и просмотра результатов.

---

### Структура репозитория

Ключевые файлы и директории проекта:

*   `docker-compose.yaml` — описание сервисов: база данных (postgres-dw, postgres-airflow), веб-сервер и планировщик Airflow, pgAdmin.
*   `Dockerfile` — кастомный образ Airflow с предустановленным dbt-core и dbt-postgres.
*   `screenshots/` — папка со скрншотами
*   `dags/`
    *   `customer_service_dag.py` — Python-скрипт DAG, определяющий последовательность задач (`dbt seed` -> `dbt run` -> `dbt test`).
*   `dbt_project/` — корневая папка dbt-проекта.
    *   `dbt_project.yml` — конфигурация проекта.
    *   `profiles.yml` — параметры подключения к PostgreSQL внутри Docker-сети.
    *   `seeds/raw_survey_data.csv` — исходный набор данных (опросы клиентов).
    *   `models/staging/stg_survey_data.sql` — SQL-модель для нормализации данных.
    *   `models/marts/customer_metrics.sql` — финальная витрина данных с расчетом метрик.

---

### Инструкция по запуску

1.  **Подготовка:** Убедиться, что установлен Docker и Docker Compose.
2.  **Сборка:** Выполнить команду `docker compose build` для создания образа.
3.  **Инициализация:** Запустить `docker compose up airflow-init` для настройки мета-базы Airflow.
4.  **Запуск:** Выполнить `docker compose up -d` для старта всех сервисов.
5.  **Доступ:**
    *   Airflow: `http://localhost:8080` (логин/пароль: admin/admin)
    *   pgAdmin: `http://localhost:5050` (логин: admin@admin.com, пароль: admin)

---

### Результаты выполнения

#### 1. Выполнение DAG и мониторинг
В ходе выполнения работы возникли технические ограничения аппаратных ресурсов (нехватка оперативной памяти в среде Kali Linux), что приводило к нестабильной работе графического веб-интерфейса Airflow при нагрузке.

В связи с этим запуск DAG был произведен успешно через **CLI (командную строку)** Docker-контейнера. Статус задачи (`queued` -> `success`) отслеживался через терминал.

**Скриншот запущенного графического веб-интерфейса Airflow:**

![Скриншот графического веб-интерфейса Airflow](/screenshots/Рисунок1.png)

**Скриншот успешного триггера DAG через терминал:**
*(На скриншоте видно успешное создание DagRun в статусе queued через docker exec)*

![Скриншот терминала с запуском DAG](/screenshots/Рисунок2.png)

#### 2. Результаты трансформации данных
Несмотря на запуск через консоль, Airflow успешно инициировал работу dbt. В целевой базе данных PostgreSQL были автоматически созданы таблицы, соответствующие логике dbt-моделей.

Данные проверены через интерфейс **pgAdmin**. Таблица `customer_metrics` содержит рассчитанные метрики (CSAT, NPS, CES) с группировкой по датам.

**Скриншот таблицы с преобразованными данными (из pgAdmin):**

![Скриншот таблицы из pgAdmin](/screenshots/Рисунок3.png)

---

### Выводы

В ходе работы были изучены принципы построения конвейеров данных (Data Pipelines) с использованием связки **Airflow + dbt**.

**Преимущества связки:**
*   **Модульность:** Логика трансформации (SQL) отделена от логики оркестрации (Python).
*   **Тестируемость:** dbt позволяет автоматически тестировать данные на уникальность и отсутствие NULL-значений.
*   **Наглядность:** Граф Airflow позволяет визуально отслеживать зависимости задач.

**Сравнение вариантов:**
Локальный вариант (Docker) оказался более требователен к ресурсам машины (RAM), что вызвало сложности с веб-интерфейсом, но позволил гибко управлять процессом через терминал и получить результат бесплатно. Облачный вариант (GCP) снял бы нагрузку с локальной машины, но потребовал бы настройки IAM и биллинга.